{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d242d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_TOKEN\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20062896",
   "metadata": {},
   "source": [
    "# Questions normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b29d6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = f\"\"\"\n",
    "You are tasked with normalizing text from customer communications with an online cosmetics shop in Czech language. The goal is to refine the text to make it structurally, grammatically, and punctuationally correct while preserving the original meaning and making only minimal necessary changes.\n",
    "\n",
    "Guidelines for text normalization:\n",
    "1. Correct obvious spelling errors\n",
    "2. Fix grammatical mistakes\n",
    "3. Adjust punctuation where necessary\n",
    "4. Improve sentence structure if it's unclear\n",
    "5. Maintain the original tone and style of the message\n",
    "6. Preserve all information from the original text\n",
    "7. Make only minimal changes required for clarity and correctness\n",
    "\n",
    "Here is the original text to be normalized:\n",
    "\n",
    "<original_text>\n",
    "{{ORIGINAL_TEXT}}\n",
    "</original_text>\n",
    "\n",
    "Please analyze the text for errors and areas that need improvement. Then, make minimal changes to normalize the text while ensuring that all original information remains intact.\n",
    "\n",
    "Provide your normalized version of the text in json format.\n",
    "Example:\n",
    "{{{{\n",
    "  \"normalized_text\": \"Dobrý den, chtěl bych si objednat rtěnku, ale nevím, jaká barva by se mi hodila. Můžete mi poradit?\",\n",
    "}}}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea6852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_fix = '\"Dobrý den, moc se nevyznám v rozdílu mezi Rozjasňujícim anti age make upem a dvousložkovým make upem. Můžete mi prosím vysvětlit hlavní rozdíl a co lépe kryje nedokonalosti? A proč se už neprodává báze pod make up? Čím tedy nahradit?\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5acd2663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AG\\AppData\\Local\\Temp\\ipykernel_19648\\622508924.py:6: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  @validator('normalized_text')\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "class NormalizedTextResponse(BaseModel):\n",
    "    normalized_text: str = Field(..., min_length=1, description=\"The normalized version of the original text\")\n",
    "    \n",
    "    @validator('normalized_text')\n",
    "    def validate_normalized_text(cls, v):\n",
    "        if not v or v.isspace():\n",
    "            raise ValueError('normalized_text cannot be empty or contain only whitespace')\n",
    "        return v.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7ccd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_question(question:str):\n",
    "    prompt = instruction.format(ORIGINAL_TEXT = question)\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-2024-11-20\",\n",
    "        input=prompt,\n",
    "    )\n",
    "\n",
    "    parsed_response = NormalizedTextResponse.model_validate_json(response.output_text)\n",
    "    json_output = parsed_response.model_dump_json()\n",
    "\n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b923f532",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for NormalizedTextResponse\n  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"normalize...tedy nahradit?\"\\n}\\n```', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m norm_question = \u001b[43mnormalize_question\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDobrý den, moc se nevyznám v rozdílu mezi Rozjasňujícim anti age make upem a dvousložkovým make upem. Můžete mi prosím vysvětlit hlavní rozdíl a co lépe kryje nedokonalosti? A proč se už neprodává báze pod make up? Čím tedy nahradit?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mnormalize_question\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m      2\u001b[39m prompt = instruction.format(ORIGINAL_TEXT = question)\n\u001b[32m      4\u001b[39m response = client.responses.create(\n\u001b[32m      5\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-2024-11-20\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[38;5;28minput\u001b[39m=prompt,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m parsed_response = \u001b[43mNormalizedTextResponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m json_output = parsed_response.model_dump_json()\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m json_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\marketing_bot\\crawl-rag\\.venv\\Lib\\site-packages\\pydantic\\main.py:746\u001b[39m, in \u001b[36mBaseModel.model_validate_json\u001b[39m\u001b[34m(cls, json_data, strict, context, by_alias, by_name)\u001b[39m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    741\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    742\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    743\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    744\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for NormalizedTextResponse\n  Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='```json\\n{\\n  \"normalize...tedy nahradit?\"\\n}\\n```', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid"
     ]
    }
   ],
   "source": [
    "norm_question = normalize_question('\"Dobrý den, moc se nevyznám v rozdílu mezi Rozjasňujícim anti age make upem a dvousložkovým make upem. Můžete mi prosím vysvětlit hlavní rozdíl a co lépe kryje nedokonalosti? A proč se už neprodává báze pod make up? Čím tedy nahradit?\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "353810ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_normalized_question(qa_data):\n",
    "    \"\"\"Create embeddings and organize for efficient retrieval\"\"\"\n",
    "    \n",
    "    enhanced_data = []\n",
    "    \n",
    "    for qa in qa_data:\n",
    "        # Create embeddings\n",
    "        norm_question = normalize_question(qa['question'])\n",
    "\n",
    "        # Add to original structure\n",
    "        enhanced_qa = {\n",
    "            **qa,  # Original data\n",
    "            'question_norm': norm_question,\n",
    "        }\n",
    "        \n",
    "        enhanced_data.append(enhanced_qa)\n",
    "    \n",
    "    return enhanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "filename = 'data/qa.json'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    qa_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd53cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_norm_questions = create_normalized_question(qa_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
